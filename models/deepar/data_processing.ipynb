{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0efcec-5d6a-42f1-ba51-bd708b30c382",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5caecba-61b2-4d74-abc2-3dd3f4c0d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from deepar_model_utils import prep_station_data\n",
    "from deepar_model_utils import get_station_data\n",
    "from deepar_model_utils import deepar_station_data\n",
    "from deepar_model_utils import write_dicts_to_file\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57915a5-a566-43e9-8f9d-c0bc52942861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bucket = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c467b0-a556-40ec-82af-c7f769b56229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = \"cleaned_historical_trips_2015_2022.csv\"\n",
    "\n",
    "#s3_data_location = f\"s3://{bucket}/{file}*\"\n",
    "#trips = pd.read_csv(s3_data_location, parse_dates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da7868-ccfd-4b52-8317-e7681b2ae238",
   "metadata": {},
   "source": [
    "5 years of trips data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf8bc0-5e3e-48a3-8ed5-1a921e414100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips = trips[(trips[\"starttime\"] > \"2017-09-01\") & (trips[\"stoptime\"] < \"2022-08-31\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775cdd8-7c03-4433-9165-e9a869d4f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start = trips[[\"starttime\", \"start station id\", \"start station name\"]]\n",
    "#trips_stop = trips[[\"stoptime\", \"end station id\", \"end station name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14bdcf-dbf9-45cd-92f5-645624351b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start.to_csv(\"model_trips_start_station_2017_2022.csv\")\n",
    "#trips_stop.to_csv(\"model_trips_stop_station_2017_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699eff3-0b34-4135-8476-3c5fc6a4534a",
   "metadata": {},
   "source": [
    "2 years of trips data to train + 3 days to test. Filter data for trip start time between 8/29/2020 and 8/31/2022 (inclusive). Filter data for trip stop time between 8/29/2020 and 8/31/2022 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c2b2e-c7b7-46f8-84d8-5adc101e1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start_poc = trips[(trips[\"starttime\"] > \"2020-08-29\") & (trips[\"starttime\"] < \"2022-09-01\")][[\"starttime\", \"start station id\"]]\n",
    "#trips_stop_poc = trips[(trips[\"stoptime\"] > \"2020-08-29\") & (trips[\"stoptime\"] < \"2022-09-01\")][[\"stoptime\", \"end station id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fac6a-c13f-4e57-821e-7b2e40dc7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start_poc.to_csv(\"../model_trips_start_station_20208029_20220831.csv\", index = False)\n",
    "#trips_stop_poc.to_csv(\"../model_trips_stop_station_20208029_20220831.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e11f6-27c7-4a11-b6b7-a7f9e6ee78ab",
   "metadata": {},
   "source": [
    "### Trip Start Station\n",
    "\n",
    "Aka how many bikes left a station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d30464-52b1-44d9-83be-96b0abe127de",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_file = \"../model_trips_start_station_20208029_20220831.csv\"\n",
    "\n",
    "#s3_start_location = f\"s3://{bucket}/{start_file}*\"\n",
    "#trips_start = pd.read_csv(s3_start_location, parse_dates = True)\n",
    "\n",
    "trips_start = pd.read_csv(start_file, parse_dates = True)\n",
    "trips_start.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bc24b-76bd-4998-acbf-1e767e6ba72b",
   "metadata": {},
   "source": [
    "Check start station id matches up with start station name. In this case, some stations have changed names due to location changes or due to a lack of data standardization. `trips_start_lookup` is a lookup table to match between the different station ids and station names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe35f71-0506-40d3-8001-bc0a3a6fa8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start[\"start station id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4803de-cff2-4e4f-93b5-af5863c583c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start[\"start station name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8c7b1-b3fc-4711-ba3e-963d21675d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start.drop_duplicates(subset = [\"start station id\", \"start station name\"]).to_csv(\"unique_start.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b1273-2258-444e-af21-ef202e7a8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start_lookup = trips_start.drop([\"Unnamed: 0\", \"starttime\"], axis = 1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78e17b-5a08-4341-8acb-1c389466d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_start_lookup.to_csv(\"trip_start_station_id_lookup.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec469a9-e774-4927-990d-45f5d5567f5c",
   "metadata": {},
   "source": [
    "Will use start station id and not start station name. From manually looking at the data, station name has more variation and very similar station names have the same station id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64602afa-9e2c-4f24-9ae2-d46571d4efe3",
   "metadata": {},
   "source": [
    "Although not terribly useful now, grouping by and getting the size will help with the resampling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f7f300-812b-4616-8524-164ec347f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_start_all_group = prep_station_data(trips_start, \"start station id\", \"starttime\")\n",
    "print(sum(trips_start_all_group[\"size\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0558529-37ec-433f-9163-9e6ff97d415e",
   "metadata": {},
   "source": [
    "Transform data into the format required by DeepAR. Not all series start at the same time or end at the same time. DeepAR allows series to start at different times, but I assume that all series have to end at the same time (or else how is prediction supposed to happen?).\n",
    "\n",
    "**Large Model**\n",
    "\n",
    "Training period is first 4 years of the data and testing period is final year of the data. Also, to train the initial model, I filtered out any stations that did not exist prior to the `test_date`. This ensures that there is corresponding training and testing data for every station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412519d-328f-4f4c-b153-a162cdeb53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"15min\" # group and sum trips by a set increment\n",
    "max_date = \"2022-08-31 23:45:00\" # make sure all series end at the same time\n",
    "train_date = \"2021-08-31\"\n",
    "test_date = \"2021-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef9d8b-5120-4242-acfe-d6679919bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_start, test_data_start = deepar_station_data(trips_start_all_group, \"start station id\", \"starttime\", freq, max_date, train_date, test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4f31f-946f-4fa8-b289-ddb2ef913927",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_start))\n",
    "print(len(test_data_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab602f0-7a93-4774-a466-472069cfd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all test data is the same length\n",
    "test_length = 0\n",
    "for i in range(len(test_data_start)):\n",
    "    test_length += len(test_data_start[i][\"target\"])\n",
    "test_length / len(test_data_start) # should be 35,040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20aa1f8-f40c-4b5c-9a10-d9fc437d4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of trips\n",
    "trips = 0\n",
    "for i in range(len(train_data_start)):\n",
    "    trips += sum(train_data_start[i][\"target\"])\n",
    "for i in range(len(test_data_start)):\n",
    "    trips += sum(test_data_start[i][\"target\"])\n",
    "trips # lost 85,515 trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196ec1e-b447-4006-9509-61ce10470491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json lines format\n",
    "write_dicts_to_file(\"train_start.json\", train_data_start)\n",
    "write_dicts_to_file(\"test_start.json\", test_data_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d872a4-8110-4434-998c-b75cc097a2b5",
   "metadata": {},
   "source": [
    "**POC Model**\n",
    "\n",
    "Training period is 4th-5th year of the data minus 3 days and testing period is final 3 days of the data. Also, to train the initial model, I filtered out any stations that did not exist prior to the `test_date`. This ensures that there is corresponding training and testing data for every station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98edc247-2e61-494a-b02a-30a935515b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"15min\" # group and sum trips by a set increment\n",
    "max_date = \"2022-08-31 23:45:00\" # make sure all series end at the same time\n",
    "train_date = \"2022-08-28\"\n",
    "test_date = \"2022-08-29\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf7e2a-8451-42aa-9160-096b6cfc74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_poc_start, test_poc_start = deepar_station_data(trips_start_all_group, \"start station id\", \"starttime\", freq, max_date, train_date, test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aac377-e5fa-4974-875b-b56110458405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retained all stations\n",
    "print(len(train_poc_start))\n",
    "print(len(test_poc_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d770c5-fc4e-4299-bb66-a9308a6ee880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all test data is the same length\n",
    "test_length = 0\n",
    "for i in range(len(test_poc_start)):\n",
    "    test_length += len(test_poc_start[i][\"target\"])\n",
    "test_length / len(test_poc_start) # should be 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9991163-0b8c-429d-8784-9a1d323b237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of trips\n",
    "trips = 0\n",
    "for i in range(len(train_poc_start)):\n",
    "    trips += sum(train_poc_start[i][\"target\"])\n",
    "for i in range(len(test_poc_start)):\n",
    "    trips += sum(test_poc_start[i][\"target\"])\n",
    "trips # retained all trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a343c-f070-41ac-a1ed-831eddf38ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json lines format\n",
    "write_dicts_to_file(\"train_poc_start.json\", train_poc_start)\n",
    "write_dicts_to_file(\"test_poc_start.json\", test_poc_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905a017-c4b9-4326-a4a2-e9c3a68684f5",
   "metadata": {},
   "source": [
    "**Plot 15-minute time series by station**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63868dc9-68dd-4497-a7b5-ddca496e0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize = (20, 20), sharex = True)\n",
    "axx = axs.ravel()\n",
    "for i in range(0, 4):\n",
    "    temp_station = [177, 436, 572, 67][i]\n",
    "    get_station_data(trips_start_all_group, \"start station id\", \"starttime\", temp_station, freq, max_date).plot(ax = axx[i])\n",
    "    axx[i].set_xlabel(\"date\")\n",
    "    axx[i].set_ylabel(\"trip count\")\n",
    "    axx[i].set_title(str(temp_station))\n",
    "    axx[i].grid(which = \"minor\", axis = \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31a28e-9fbc-4ccd-a011-23ea99253678",
   "metadata": {},
   "source": [
    "### Trip End Station\n",
    "\n",
    "Aka how many bikes arrived at a station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83369c0d-dd81-48af-b780-c35348d93d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_file = \"../model_trips_stop_station_20208029_20220831.csv\"\n",
    "\n",
    "#s3_end_location = f\"s3://{bucket}/{end_file}*\"\n",
    "#trips_end = pd.read_csv(s3_end_location, parse_dates = True)\n",
    "\n",
    "trips_stop = pd.read_csv(stop_file, parse_dates = True)\n",
    "trips_stop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06d47d-9a54-4d48-a194-75ccc74ba12f",
   "metadata": {},
   "source": [
    "Although not terribly useful now, grouping by and getting the size will help with the resampling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd42245-7a48-4930-959b-e83c124dd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_stop_all_group = prep_station_data(trips_stop, \"end station id\", \"stoptime\")\n",
    "print(sum(trips_stop_all_group[\"size\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0d4c5-58ca-4ce5-b4ab-de8ab57afb7b",
   "metadata": {},
   "source": [
    "Transform data into the format required by DeepAR. Not all series start at the same time or end at the same time. DeepAR allows series to start at different times, but I assume that all series have to end at the same time (or else how is prediction supposed to happen?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c940d-1ddf-4351-aa9d-e9a277ae402f",
   "metadata": {},
   "source": [
    "**POC Model**\n",
    "\n",
    "Training period is 4th-5th year of the data minus 3 days and testing period is final 3 days of the data. Also, to train the initial model, I filtered out any stations that did not exist prior to the `test_date`. This ensures that there is corresponding training and testing data for every station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ea153-4e27-49ad-afdf-6d2409f19f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"15min\" # group and sum trips by a set increment\n",
    "max_date = \"2022-08-31 23:45:00\" # make sure all series end at the same time\n",
    "train_date = \"2022-08-28\"\n",
    "test_date = \"2022-08-29\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69110d7-f320-4cee-82a9-f1294ef4ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_poc_stop, test_poc_stop = deepar_station_data(trips_stop_all_group, \"end station id\", \"stoptime\", freq, max_date, train_date, test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f537052-73a0-4b7d-b001-3c82123e73c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retained all but 1 station\n",
    "print(len(train_poc_stop))\n",
    "print(len(test_poc_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6e76e-eac6-4bcc-a1f8-e59b18e9a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all test data is the same length\n",
    "test_length = 0\n",
    "for i in range(len(test_poc_stop)):\n",
    "    test_length += len(test_poc_stop[i][\"target\"])\n",
    "test_length / len(test_poc_stop) # should be 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac301b3c-537b-4dc7-a169-f21b4bea0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of trips\n",
    "trips = 0\n",
    "for i in range(len(train_poc_stop)):\n",
    "    trips += sum(train_poc_stop[i][\"target\"])\n",
    "for i in range(len(test_poc_stop)):\n",
    "    trips += sum(test_poc_stop[i][\"target\"])\n",
    "trips # lost 5 trips due to the 1 station loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db1cdc-a35e-4564-b197-7d2dda59fff1",
   "metadata": {},
   "source": [
    "Station 572 w/ 5 trips was dropped b/c the first trip that ended there was after the `test_date` of 8/29/2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4a2f5-ef39-4efc-b4e5-6f69c34ac353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json lines format\n",
    "write_dicts_to_file(\"train_poc_stop.json\", train_poc_stop)\n",
    "write_dicts_to_file(\"test_poc_stop.json\", test_poc_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12498d27-ad54-44de-829b-a682539c44c0",
   "metadata": {},
   "source": [
    "**Plot 15-minute time series by station**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be3132-c48c-4c39-aeea-c59ecb240ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize = (20, 20), sharex = True)\n",
    "axx = axs.ravel()\n",
    "for i in range(0, 4):\n",
    "    temp_station = [177, 436, 572, 67][i]\n",
    "    get_station_data(trips_stop_all_group, \"end station id\", \"stoptime\", temp_station, freq, max_date).plot(ax = axx[i])\n",
    "    axx[i].set_xlabel(\"date\")\n",
    "    axx[i].set_ylabel(\"trip count\")\n",
    "    axx[i].set_title(str(temp_station))\n",
    "    axx[i].grid(which = \"minor\", axis = \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e260b163-736f-407a-afd6-065697bcc319",
   "metadata": {},
   "source": [
    "### Master Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83d9cb-b6e7-4545-8814-7253f3a9302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"15min\" # group and sum trips by a set increment\n",
    "max_date = \"2022-08-28 23:45:00\" # make sure all series end at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4012f777-d68f-4fce-86ce-cf1e0b053759",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame()\n",
    "for station in tqdm(trips_start_all_group[\"start station id\"].unique()):\n",
    "    trip_station = pd.DataFrame(get_station_data(trips_start_all_group, \"start station id\", \"starttime\", station, freq, max_date)[\"size\"])\n",
    "    trip_station[\"timestamp\"] = trip_station.index\n",
    "    trip_station = trip_station.reset_index(drop = True)\n",
    "    trip_station[\"station\"] = station\n",
    "    \n",
    "    train_data = pd.concat([train_data, trip_station], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934ca28-2004-4c82-a14b-4463b42074fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_data[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b27c4c-a585-4954-9bb1-ac817c82c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"../../datasets/trip_start_station_train_20200829-20220828.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af202de8-4db6-4b44-847f-37fa186a75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame()\n",
    "for station in tqdm(trips_stop_all_group[\"end station id\"].unique()):\n",
    "    if station != 572:\n",
    "        trip_station = pd.DataFrame(get_station_data(trips_stop_all_group, \"end station id\", \"stoptime\", station, freq, max_date)[\"size\"])\n",
    "        trip_station[\"timestamp\"] = trip_station.index\n",
    "        trip_station = trip_station.reset_index(drop = True)\n",
    "        trip_station[\"station\"] = station\n",
    "    \n",
    "        train_data = pd.concat([train_data, trip_station], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5825e-e23c-4747-88a3-1aac798bc12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_data[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296aa9dc-d594-434d-8c83-44328860640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"../../datasets/trip_stop_station_train_20200829-20220828.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318391af-ef2a-451c-8dcf-00c5da40404c",
   "metadata": {},
   "source": [
    "### Master Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb97964-361b-4272-9b97-af04fa566033",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"15min\" # group and sum trips by a set increment\n",
    "test_start = \"2022-08-29 00:00:00\"\n",
    "max_date = \"2022-08-31 23:45:00\" # make sure all series end at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76757ee-597a-46be-9039-428c0a529506",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame()\n",
    "for station in tqdm(trips_start_all_group[\"start station id\"].unique()):\n",
    "    trip_station = pd.DataFrame(get_station_data(trips_start_all_group, \"start station id\", \"starttime\", station, freq, max_date, cluster = True, min_date = test_start).loc[test_start:][\"size\"])\n",
    "    trip_station[\"timestamp\"] = trip_station.index\n",
    "    trip_station = trip_station.reset_index(drop = True)\n",
    "    trip_station[\"station\"] = station\n",
    "    \n",
    "    eval_data = pd.concat([eval_data, trip_station], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57abbd7e-c617-457c-ac7d-8f04258fb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(eval_data[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb4736-821a-41b7-93c7-6c255e27ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data.to_pickle(\"../../datasets/trip_start_station_eval_20220829-20220831.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0761bc-2896-4eb0-a269-6a3586e86f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame()\n",
    "for station in tqdm(trips_stop_all_group[\"end station id\"].unique()):\n",
    "    if station != 572:\n",
    "        trip_station = pd.DataFrame(get_station_data(trips_stop_all_group, \"end station id\", \"stoptime\", station, freq, max_date, cluster = True, min_date = test_start).loc[test_start:][\"size\"])\n",
    "        trip_station[\"timestamp\"] = trip_station.index\n",
    "        trip_station = trip_station.reset_index(drop = True)\n",
    "        trip_station[\"station\"] = station\n",
    "    \n",
    "        eval_data = pd.concat([eval_data, trip_station], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16c343-3d30-42b9-bab7-58a80a3c1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(eval_data[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0ad28-03c0-4347-858b-462022234e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data.to_pickle(\"../../datasets/trip_stop_station_eval_20220829-20220831.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03eeea2-dc49-4bb6-901f-c48ee3bcdc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
