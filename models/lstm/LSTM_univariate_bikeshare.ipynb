{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljnlIOfFnudI"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w_SCKkU6G2gx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDF-CcjhjjPt"
   },
   "source": [
    "### Load train and test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VQAStYosezQH"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_2022_08_28.csv')\n",
    "test_df = pd.read_csv('test_df_2022_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6ltmel6-eqkA"
   },
   "outputs": [],
   "source": [
    "# limit to just one station\n",
    "train_df_subset = train_df[train_df['station'] == 16]\n",
    "test_df_subset = test_df[test_df['station'] == 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ToNKYd0qG3PH"
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMLLh8NWjox4"
   },
   "source": [
    "## Split train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nT5GAKo_fyBX"
   },
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv('train_df_2022_08_28.csv', usecols=[5], engine='python')\n",
    "test_dataframe = pd.read_csv('test_df_2022_08.csv', usecols=[5], engine='python')\n",
    "dataframe = pd.concat([train_dataframe, test_dataframe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "E0SZ-C0IHL4Y"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "# dataframe = pd.read_csv('train_df_2022_08_28.csv', usecols=[5], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XPh7YoCdHNci"
   },
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjaO6cBIHPLp",
    "outputId": "be94a105-d8a2-4e95-8b58-44c804195959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47880 144648\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_size = 47880 # the number of rows in the training dataset \n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XAJOqrpEHRBl"
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "syqzP3-sHVjR"
   },
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQU6V7Hag8xL"
   },
   "source": [
    "It takes 50s per epoch, for just 1 day of data for training. There are also 504 stations.\n",
    "\n",
    "Each model takes 50*3 ~= 4 minutes.\n",
    "\n",
    "(4*504)/60 = 33.6 hours = 8 full days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5SFz9K8kKJv"
   },
   "source": [
    "## Building and evaluating model\n",
    "\n",
    "The LSTM model performance is better than the baseline for station 16. \n",
    "\n",
    "* LSTM RMSE: 0.92\n",
    "* Baseline RMSE: 1.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxBWSSsQHSZR",
    "outputId": "16a78b77-19e6-4156-d29c-d85a9c914d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "47878/47878 - 49s - loss: 0.0020 - 49s/epoch - 1ms/step\n",
      "Epoch 2/2\n",
      "47878/47878 - 48s - loss: 0.0019 - 48s/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1239d68c50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=2, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kiqMrSbHfbn",
    "outputId": "b9fa64e2-6888-4886-eef8-a805b53dd8d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497/1497 [==============================] - 2s 934us/step\n",
      "4521/4521 [==============================] - 4s 915us/step\n",
      "Train Score: 1.05 RMSE\n",
      "Test Score: 0.92 RMSE\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvHf8ao2n54f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
